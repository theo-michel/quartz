<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="This is a project analysing the results of the dreamer paper.
 Install ubuntu Install softwareÂ  Choose right Repository Get Pytorch Code Try to run it localy Try to run everything on the cluster with atari games Make it run with Minigrid (almost done) Extract Model using PyTorch Create demo of model extractionÂ  Create Gif of Pong Extract the model using MlFlow Extract the test dirs from past training Understand what is in test_dirs/eval_dirs Extract and evaluate the latest of a model Undestand the training precisly What is Model eval or Actor/critic eval looking like Revisit the explainatory video When to stop the training ?"><meta property="og:title" content><meta property="og:description" content="This is a project analysing the results of the dreamer paper.
 Install ubuntu Install softwareÂ  Choose right Repository Get Pytorch Code Try to run it localy Try to run everything on the cluster with atari games Make it run with Minigrid (almost done) Extract Model using PyTorch Create demo of model extractionÂ  Create Gif of Pong Extract the model using MlFlow Extract the test dirs from past training Understand what is in test_dirs/eval_dirs Extract and evaluate the latest of a model Undestand the training precisly What is Model eval or Actor/critic eval looking like Revisit the explainatory video When to stop the training ?"><meta property="og:type" content="website"><meta property="og:image" content="https://theo-michel.github.io/quartz/icon.png"><meta property="og:url" content="https://theo-michel.github.io/quartz/Science/Dreamer-Project/"><meta property="og:width" content="200"><meta property="og:height" content="200"><meta name=twitter:card content="summary"><meta name=twitter:title content><meta name=twitter:description content="This is a project analysing the results of the dreamer paper.
 Install ubuntu Install softwareÂ  Choose right Repository Get Pytorch Code Try to run it localy Try to run everything on the cluster with atari games Make it run with Minigrid (almost done) Extract Model using PyTorch Create demo of model extractionÂ  Create Gif of Pong Extract the model using MlFlow Extract the test dirs from past training Understand what is in test_dirs/eval_dirs Extract and evaluate the latest of a model Undestand the training precisly What is Model eval or Actor/critic eval looking like Revisit the explainatory video When to stop the training ?"><meta name=twitter:image content="https://theo-michel.github.io/quartz/icon.png"><meta name=twitter:site content="_jzhao"><title>ðŸª´ Quartz 3.3</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://theo-michel.github.io/quartz//icon.png><link href=https://theo-michel.github.io/quartz/styles.b369a84b3c6e6bfd686ad1f9da65641c.min.css rel=stylesheet><link href=https://theo-michel.github.io/quartz/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://theo-michel.github.io/quartz/js/darkmode.c8f8d7ab42782baefb49de2020b64bb7.min.js></script>
<script src=https://theo-michel.github.io/quartz/js/util.a0ccf91e1937fe761a74da4946452710.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/core@1.2.1></script>
<script src=https://cdn.jsdelivr.net/npm/@floating-ui/dom@1.2.1></script>
<script async src=https://theo-michel.github.io/quartz/js/popover.aa9bc99c7c38d3ae9538f218f1416adb.min.js></script>
<script defer src=https://theo-michel.github.io/quartz/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://theo-michel.github.io/quartz/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://theo-michel.github.io/quartz/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://theo-michel.github.io/quartz/",fetchData=Promise.all([fetch("https://theo-michel.github.io/quartz/indices/linkIndex.ddee9e06e396ccc6f015c2f371002a68.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://theo-michel.github.io/quartz/indices/contentIndex.3fefc0e9cf021e40e47bd53f057e6f5a.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://theo-michel.github.io/quartz",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://theo-michel.github.io/quartz",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()});function a(n){const e=n.target,t=e.className.split(" "),s=t.includes("broken"),o=t.includes("internal-link");plausible("Link Click",{props:{href:e.href,broken:s,internal:o,graph:!1}})}const r=document.querySelectorAll("a");for(link of r)link.className.includes("root-title")&&link.addEventListener("click",a,{once:!0})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'â€™':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/theo-michel.github.io\/quartz\/js\/router.d6fe6bd821db9ea97f9aeefae814d8e7.min.js"
    attachSPARouting(init, render)
  </script><script defer data-domain=theo-michel.github.io/quartz src=https://plausible.io/js/script.js></script>
<script>window.plausible=window.plausible||function(){(window.plausible.q=window.plausible.q||[]).push(arguments)}</script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://theo-michel.github.io/quartz/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a class=root-title href=https://theo-michel.github.io/quartz/>ðŸª´ Quartz 3.3</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><p class=meta>Last updated
Mar 13, 2023
<a href=https://github.com/jackyzha0/quartz/tree/hugo/content/Science/Dreamer%20Project.md rel=noopener>Edit Source</a></p><ul class=tags></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#todo-next>TODO NEXT</a></li></ol><ol><li><ol><li><a href=#extract-model>Extract Model</a></li></ol></li><li><a href=#notes-installation>Notes installation</a></li></ol><ol><li><ol><li><a href=#trainer>Trainer</a></li><li><a href=#and-generator>And generator</a></li></ol></li><li><a href=#model-extraction-and-manipulation>Model extraction and manipulation</a><ol><li><a href=#using-mlflow>Using MlFlow</a></li></ol></li><li><a href=#extract-path-to-pt-file>Extract path to pt file</a></li><li><a href=#launch-mingrid-training>Launch Mingrid training</a><ol><li></li></ol></li><li><a href=#adventure>Adventure</a><ol><li><a href=#gif-creation>Gif creation</a></li><li><a href=#model-extraction-and-manipulation-1>Model extraction and manipulation</a></li><li><a href=#minigrid-dreams>Minigrid Dreams</a></li><li><a href=#figure-creation>Figure creation</a></li><li><a href=#things-i-learned-about-ssh>Things I learned about ssh</a></li></ol></li></ol><ol><li><ol><li><a href=#definitions>Definitions</a></li></ol></li><li><a href=#usefull-commands>Usefull Commands</a><ol><li></li></ol></li><li><a href=#metrics>Metrics</a></li><li><a href=#dream-interpretation>Dream interpretation</a></li></ol><ol><li><a href=#quick-notes>Quick notes</a></li></ol></nav></details></aside><p>This is a project analysing the results of the dreamer paper.</p><ul><li><input checked disabled type=checkbox> Install ubuntu</li><li><input checked disabled type=checkbox> Install softwareÂ </li><li><input checked disabled type=checkbox> Choose right Repository</li><li><input checked disabled type=checkbox> Get Pytorch Code</li><li><input checked disabled type=checkbox> Try to run it localy</li><li><input checked disabled type=checkbox> Try to run everything on the cluster with atari games</li><li><input checked disabled type=checkbox> Make it run with Minigrid (almost done)</li><li><input checked disabled type=checkbox> Extract Model using PyTorch</li><li><input checked disabled type=checkbox> Create demo of model extractionÂ </li><li><input checked disabled type=checkbox> Create Gif of Pong</li><li><input checked disabled type=checkbox> Extract the model using MlFlow</li><li><input checked disabled type=checkbox> Extract the test dirs from past training</li><li><input disabled type=checkbox> Understand what is in test_dirs/eval_dirs</li><li><input checked disabled type=checkbox> Extract and evaluate the latest of a model</li><li><input checked disabled type=checkbox> Undestand the training precisly</li><li><input disabled type=checkbox> What is Model eval or Actor/critic eval looking like</li><li><input disabled type=checkbox> Revisit the explainatory video</li><li><input disabled type=checkbox> When to stop the training ?</li><li><input checked disabled type=checkbox> Evaluate the Model</li><li><input disabled type=checkbox> Find the right hyperparameters for Minigrid</li><li><input disabled type=checkbox> Create Gif of Minigrid(Hard)</li><li><input disabled type=checkbox> Run the model in the gym Independently</li><li><input checked disabled type=checkbox> Train a good model on Minigrid</li><li><input disabled type=checkbox> Create figures (Need to have a lot of training, and different models ? ~)</li><li><input disabled type=checkbox> Compare performance with state of the art on Minigrid</li><li><input checked disabled type=checkbox> Share fork on Github</li><li><input disabled type=checkbox> Modify gym environment</li></ul><a href=#todo-next><h2 id=todo-next><span class=hanchor arialabel=Anchor># </span>TODO NEXT</h2></a><ul><li><p><input disabled type=checkbox> Try other envs to learn how to adapt an env</p><ul><li><input checked disabled type=checkbox> Minigrid add another minigrid</li><li><input checked disabled type=checkbox> 4 rooms works out of the box</li><li><input checked disabled type=checkbox> Door Key works out of the box</li><li><input checked disabled type=checkbox> memory works out of the box</li><li><input disabled type=checkbox> Blocked unlock pickup doesn&rsquo;t work because of npz save still doesnt work</li><li><input checked disabled type=checkbox> - <code>MiniGrid-KeyCorridorS3R1-v0</code> is working</li><li><input checked disabled type=checkbox> - <code>MiniGrid-KeyCorridorS5R3-v0</code> working</li><li><input checked disabled type=checkbox> Try to make the minigrid save work for non square minigrid envs
To change the minigrid game carreful with <strong>image channels</strong> <strong>map channels</strong> But doesnt work yet</li></ul></li><li><p><input disabled type=checkbox> Understand latent variables of the world model on atari</p></li><li><p><input checked disabled type=checkbox> Launch long training of a model screen!
<code>python launch.py --config defaults minigrid --env_id MiniGrid-DoorKey-8x8-v0 --probe_model none</code></p></li><li><p><input disabled type=checkbox> How to get more precise control of the videos and environments ?</p></li><li><p><input disabled type=checkbox> Extract World Model and play with the input and see the output change</p></li><li><p><input checked disabled type=checkbox> Record video of the trained model</p></li><li><p><input disabled type=checkbox> Do a completly different env</p></li><li><p><input disabled type=checkbox> Sokoban
<a href=https://alexandervandekleut.github.io/gym-wrappers/ rel=noopener>Gym Wraper tutorial</a>
<a href=https://www.gymlibrary.dev/api/wrappers/ rel=noopener>Gym Wrapper Doc</a></p></li><li><p><input disabled type=checkbox> Create a gym env
<a href=/quartz/Science/Creating-a-gym-environment-for-Dreamer rel=noopener class=internal-link data-src=/quartz/Science/Creating-a-gym-environment-for-Dreamer>Creating a gym environment for Dreamer</a></p></li><li><p><input checked disabled type=checkbox> Check if i can get the video of the evaluation from the training directly (You probably can as in Dreamer.py l.173 it is said : &ldquo;The tensors are intentionally named same as in tensors, so the logged npz looks the same for dreamed or not&rdquo;) So you can probably get non dreamed npz</p></li><li><p><input checked disabled type=checkbox> STOP ADVENTURE TRAINING <code>python launch.py --configs defaults atari --env_id Atari-Adventure-v5</code></p></li></ul><a href=#work-in-progress><h1 id=work-in-progress><span class=hanchor arialabel=Anchor># </span>Work in Progress</h1></a><p><code>python launch.py --config defaults sokoban --probe_model none</code>(just changed the action dim)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x24576 and 1536x1000)
Not yet Working
<code>python launch.py --configs defaults atari --env_id MsPacman-v0</code>
We don&rsquo;t have the ROM</p><p>Works</p><p><code>python launch.py --configs defaults atari --env_id Atari-Alien-V5</code>
(A bit like pacman)</p><ul><li><p><input checked disabled type=checkbox> Stop Training
Best step : 2099900</p></li><li><p><input disabled type=checkbox> Make recordings lest regular</p></li><li><p><input disabled type=checkbox> Sokoban
<code>python launch.py --configs defaults atari --env_id Sokoban</code></p></li><li><p><input disabled type=checkbox> Try fixing this Sokoban with the appropriate paremeters (Atari like)fixing this with the appropriate paremeters (Atari l)</p></li><li><p><input checked disabled type=checkbox> Maybe the Minigrid problem was a reshap problem ?</p></li><li><p><input checked disabled type=checkbox> Find more efficient way of using the artifacts ( Just move Make gif)</p></li><li><p><input checked disabled type=checkbox> Minigrid decoding need to be done manually, or with a function, eval is not human readable, Maybe there is a parameter in config that makes it all human readable ( It is actually just really dark)</p></li><li><p><input checked disabled type=checkbox> Fix Model extraction works but RGB Colors look of</p></li><li><p><input disabled type=checkbox> Incremental Mini-Grid</p></li><li><p><input disabled type=checkbox> Iterate over the latent variables</p></li><li><p><input disabled type=checkbox> over the latent variables and select the ones that makes the biggest difference in the output</p></li><li><p><input disabled type=checkbox> Maybe use interpretable ai stuff</p></li><li><p><input checked disabled type=checkbox> Replace args in jupyter</p></li><li><p><input checked disabled type=checkbox> Model interpretation make each variable to zero and see the results</p></li><li><p><input disabled type=checkbox> Try to get better states</p></li><li><p><input disabled type=checkbox> 32,32 state</p></li><li><p><input disabled type=checkbox> Problem the states are optained with untrained model, but obs is fine</p></li><li><p><input disabled type=checkbox> And is the model using state and obs</p></li><li><p><input disabled type=checkbox> Can i restard the training with a good model ?</p></li><li><p><input disabled type=checkbox> I want it to predict a long time into the future</p></li><li><p><input disabled type=checkbox> When does it do d2_wm_dream and how</p></li><li><p><input disabled type=checkbox> I am using the forward from the model and not from the World Model, in order to predict longuer into the future like in the second figure of the graphmodel and not from the World Model, in order to predict longuer into the future like in the second fi</p></li><li><p><input disabled type=checkbox> Problem with obs dim becomes wrong T Maybe juste on dim to much ?</p></li></ul><p><strong>do_open_loop</strong> is if we are using the first or second image on the paper, if we are getting a new obs everytime or using the estimated $\hat{z}$.</p><p><strong>d2_wm_open_</strong> ?
d2_wm_dream is what we are looking for</p><p><strong>Problem</strong> It is reproducable, not that precisely, should i do an average ?</p><p>A couple of min about the paper
What I was trying to understand
What I did results what i tried didnt workout
what remains open
we where trying to understand the applicability to more complex scenarios
Show videos and images
Show graphs a little</p><ul><li><input disabled type=checkbox> Send bullet point for the presentation</li></ul><p>15 mins
then questions</p><a href=#extract-model><h3 id=extract-model><span class=hanchor arialabel=Anchor># </span>Extract Model</h3></a><p><code>python extract_model.py --configs defaults atari --env_id Atari-Adventure-v5</code></p><p>``python launch.py &ndash;configs defaults atari &ndash;env_id Atari-Breakout
(210, 160, 3)
<code>python launch.py --configs defaults atari --env_id Atari-Pong</code></p><p>we needed for installation the</p><a href=#notes-installation><h2 id=notes-installation><span class=hanchor arialabel=Anchor># </span>Notes installation</h2></a><p>pleasures downgrad protobuf
pip install protobuf==3.20.*
pip install gym-minigrid==0.0.6
only works with older gym and gym-minigrid version</p><p>To make faster :
Choose CPU and GPU
Pytorch torch 2.0</p><a href=#code-understanding><h1 id=code-understanding><span class=hanchor arialabel=Anchor># </span>Code understanding</h1></a><p>2 mains parts</p><a href=#trainer><h3 id=trainer><span class=hanchor arialabel=Anchor># </span>Trainer</h3></a><a href=#dreamerpy><h4 id=dreamerpy><span class=hanchor arialabel=Anchor># </span>Dreamer.py</h4></a><p>The model is here</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>104 if conf.model == &#39;dreamer&#39;:
</span></span><span class=line><span class=cl>105 model = Dreamer(conf)
</span></span></code></pre></td></tr></table></div></div><p>Maybe <strong>inference</strong> usefull to use the model ?
<strong>Inference</strong> to use the model</p><a href=#and-generator><h3 id=and-generator><span class=hanchor arialabel=Anchor># </span>And generator</h3></a><p>Create the map of the world ?
What is this prob concept ?</p><a href=#model-extraction-and-manipulation><h2 id=model-extraction-and-manipulation><span class=hanchor arialabel=Anchor># </span>Model extraction and manipulation</h2></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>mlflow ui
</span></span><span class=line><span class=cl>If error run 
</span></span><span class=line><span class=cl>lsof -i tcp:5000
</span></span><span class=line><span class=cl>kill PID  #PID the PID of the process using the port
</span></span></code></pre></td></tr></table></div></div><p>Understand MLFlow model storage
Called artifacts</p><a href=#using-mlflow><h3 id=using-mlflow><span class=hanchor arialabel=Anchor># </span>Using MlFlow</h3></a><ul><li><input disabled type=checkbox> Later is ok</li></ul><a href=#extract-path-to-pt-file><h2 id=extract-path-to-pt-file><span class=hanchor arialabel=Anchor># </span>Extract path to pt file</h2></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>model = Dreamer()
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>model.load_state_dict(torch.load(&#34;pydreamer/mlruns/0/3a77758b70034116b3c5285f83440df1/artifacts/checkpoints/latest.pt&#34;))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>model.eval()
</span></span></code></pre></td></tr></table></div></div><p>But we also have a <em>tools.mlflow_load_checkpoint</em> function
This function only serves to load an active checkpoint
not a past one</p><ul><li><input checked disabled type=checkbox> Try to find a point where they load a past model
It is used in <em>generator.py</em></li><li><input checked disabled type=checkbox> one episode = one a sequence of states, actions and rewards, which ends with terminal state. For example, playing an entire game can be considered as one episode, the terminal state being reached when one player loses/wins/draws. Sometime, one may prefer to define one episode as several games (example: &ldquo;each episode is a few dozen games, because the games go up to score of 21 for either player&rdquo;).Load a past model latest.pt &ldquo;By Hand&rdquo;
I extracted the relevant things from the pt file, you can do it without MlFlow for now
I just took the functions need from <code>tools.mlflow_load_checkpoint.</code></li></ul><a href=#launch-mingrid-training><h2 id=launch-mingrid-training><span class=hanchor arialabel=Anchor># </span>Launch Mingrid training</h2></a><p>Minigrid doesn&rsquo;t support prob training so you have to disable it
Plus the default Id is not the right one
See
<a href=/quartz/ rel=noopener class=internal-link data-src=/quartz/>github issue</a></p><p><code>python launch.py --config defaults minigrid debug --env_id MiniGrid-Empty-8x8-v0 --probe_model none</code></p><a href=#minigridpy><h4 id=minigridpy><span class=hanchor arialabel=Anchor># </span>minigrid.py</h4></a><a href=#adventure><h2 id=adventure><span class=hanchor arialabel=Anchor># </span>Adventure</h2></a><p><code>python launch.py --configs defaults atari --env_id Atari-Adventure-v5</code></p><p>Launched id 261d3a26b2b842ec990a8d0a5d6111ac
Learned a little but the agent still makes randon actions and doesn&rsquo;t show progress
Adventure
No rewards</p><a href=#gif-creation><h3 id=gif-creation><span class=hanchor arialabel=Anchor># </span>Gif creation</h3></a><p>need to move the ml run into the MlRuns folder closest to th ?</p><a href=#model-extraction-and-manipulation-1><h3 id=model-extraction-and-manipulation-1><span class=hanchor arialabel=Anchor># </span>Model extraction and manipulation</h3></a><p>e juptyter file
Then run <em>make_gif</em>
<strong>Don&rsquo;t know if either in RGB or RGBA the dreams make sense
Or if there is a Decoding to do</strong>
<a href=https://github.com/rohitrango/gym-minigrid rel=noopener>https://github.com/rohitrango/gym-minigrid</a> He says it is 7 7 3
Or it just doesn&rsquo;t work for mingrid</p><p><code>env = RGBImgPartialObsWrapper(env)</code></p><a href=#minigrid-dreams><h3 id=minigrid-dreams><span class=hanchor arialabel=Anchor># </span>Minigrid Dreams</h3></a><p>I dont know if those are encoded somhow
Or if those are
<strong>I think maybe he did the weird encoding in order to make the dreams readable !</strong></p><a href=#figure-creation><h3 id=figure-creation><span class=hanchor arialabel=Anchor># </span>Figure creation</h3></a><p>Run the export ?</p><p>â€‹ï¿¼ï¿¼ï¿¼Model extraction and manipulation</p><p>use the <code>mlflow_export.ipynb</code> file to export the results to csv
Display the csv thanks to <code>figures.ipynb</code></p><p>An average is done over multiple runs, so i can&rsquo;t really plot anythin yet.</p><a href=#things-i-learned-about-ssh><h3 id=things-i-learned-about-ssh><span class=hanchor arialabel=Anchor># </span>Things I learned about ssh</h3></a><p><a href=/quartz/Science/SSH rel=noopener class=internal-link data-src=/quartz/Science/SSH>SSH</a></p><p>There is commented code to make rectegular stuf square</p><a href=#evaluation><h1 id=evaluation><span class=hanchor arialabel=Anchor># </span>Evaluation</h1></a><p>Theone episode = one a sequence of states, actions and rewards, which ends with terminal state. For example, playing an entire game can be considered as one episode, the terminal state being reached when one player loses/wins/draws. Sometime, one may prefer to define one episode as several games (example: &ldquo;each episode is a few dozen games, because the games go up to score of 21 for either player&rdquo;). act of taking our model, and making it play the game, record the score
Just exctracted the code from the training and evaluation.</p><p>But what data to evaluate it, and how exactly ?</p><p>Explanation of the <code>evaluate</code></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-mysql data-lang=mysql><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>prefix</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>string</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=n>used</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>prefix</span><span class=w> </span><span class=n>output</span><span class=w> </span><span class=n>log</span><span class=w> </span><span class=n>messages</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>steps</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>an</span><span class=w> </span><span class=kt>integer</span><span class=w> </span><span class=n>representing</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>number</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>steps</span><span class=w> </span><span class=k>or</span><span class=w> </span><span class=n>iterations</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=n>have</span><span class=w> </span><span class=n>been</span><span class=w> </span><span class=n>performed</span><span class=w> </span><span class=n>so</span><span class=w> </span><span class=n>far</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>model</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>an</span><span class=w> </span><span class=n>instance</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=o>`</span><span class=n>Dreamer</span><span class=o>`</span><span class=w> </span><span class=n>class</span><span class=p>,</span><span class=w> </span><span class=n>which</span><span class=w> </span><span class=n>appears</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>be</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>machine</span><span class=w> </span><span class=n>learning</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>being</span><span class=w> </span><span class=n>evaluated</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>data_iterator</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>an</span><span class=w> </span><span class=n>iterator</span><span class=w> </span><span class=n>that</span><span class=w> </span><span class=n>produces</span><span class=w> </span><span class=n>batches</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>be</span><span class=w> </span><span class=n>used</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>evaluating</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>device</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=nf>device</span><span class=w> </span><span class=p>(</span><span class=n>e</span><span class=p>.</span><span class=n>g</span><span class=p>.</span><span class=w> </span><span class=n>CPU</span><span class=w> </span><span class=k>or</span><span class=w> </span><span class=n>GPU</span><span class=p>)</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>which</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>run</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>eval_batches</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>number</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>batches</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>evaluate</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=k>on</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>eval_samples</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>number</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>samples</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=k>use</span><span class=w> </span><span class=k>when</span><span class=w> </span><span class=n>evaluating</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>keep_state</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>boolean</span><span class=w> </span><span class=n>indicating</span><span class=w> </span><span class=n>whether</span><span class=w> </span><span class=k>or</span><span class=w> </span><span class=k>not</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>keep</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>state</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=k>between</span><span class=w> </span><span class=n>batches</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>save_size</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>size</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>sample</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>save</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>future</span><span class=w> </span><span class=n>reference</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=o>-</span><span class=w>   </span><span class=o>`</span><span class=n>conf</span><span class=o>`</span><span class=p>:</span><span class=w> </span><span class=n>an</span><span class=w> </span><span class=n>object</span><span class=w> </span><span class=n>containing</span><span class=w> </span><span class=n>configuration</span><span class=w> </span><span class=n>options</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>evaluation</span><span class=w> </span><span class=n>process</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=n>The</span><span class=w> </span><span class=n>function</span><span class=w> </span><span class=n>performs</span><span class=w> </span><span class=n>evaluation</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=n>two</span><span class=w> </span><span class=n>steps</span><span class=p>:</span><span class=w> </span><span class=n>first</span><span class=p>,</span><span class=w> </span><span class=n>it</span><span class=w> </span><span class=n>performs</span><span class=w> </span><span class=s2>&#34;open loop&#34;</span><span class=w> </span><span class=n>evaluation</span><span class=p>,</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=n>which</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>makes</span><span class=w> </span><span class=n>predictions</span><span class=w> </span><span class=n>based</span><span class=w> </span><span class=k>on</span><span class=w> </span><span class=n>an</span><span class=w> </span><span class=n>initial</span><span class=w> </span><span class=kt>set</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>observations</span><span class=p>,</span><span class=w> </span><span class=n>but</span><span class=w> </span><span class=n>does</span><span class=w> </span><span class=k>not</span><span class=w> </span><span class=n>receive</span><span class=w> </span><span class=n>additional</span><span class=w> </span><span class=n>feedback</span><span class=p>.</span><span class=w> </span><span class=n>Second</span><span class=p>,</span><span class=w> </span><span class=n>it</span><span class=w> </span><span class=n>performs</span><span class=w> </span><span class=s2>&#34;closed loop&#34;</span><span class=w> </span><span class=n>evaluation</span><span class=p>,</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=n>which</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>receives</span><span class=w> </span><span class=n>additional</span><span class=w> </span><span class=n>feedback</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>form</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>rewards</span><span class=p>.</span><span class=w> </span><span class=k>For</span><span class=w> </span><span class=k>each</span><span class=w> </span><span class=n>step</span><span class=p>,</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>function</span><span class=w> </span><span class=n>logs</span><span class=w> </span><span class=n>various</span><span class=w> </span><span class=n>performance</span><span class=w> </span><span class=n>metrics</span><span class=p>,</span><span class=w> </span><span class=n>including</span><span class=w> </span><span class=n>log</span><span class=w> </span><span class=n>probabilities</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>losses</span><span class=p>.</span><span class=w> </span><span class=n>Additionally</span><span class=p>,</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>function</span><span class=w> </span><span class=n>logs</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=kt>time</span><span class=w> </span><span class=n>it</span><span class=w> </span><span class=n>takes</span><span class=w> </span><span class=k>to</span><span class=w> </span><span class=n>perform</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>evaluation</span><span class=p>,</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>can</span><span class=w> </span><span class=n>save</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>sample</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>outputs</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>future</span><span class=w> </span><span class=n>reference</span><span class=p>.</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>test_dirs
[&lsquo;file:///home/theomichel/work/pyDreamer/pydreamer/mlruns/0/afc956ebbaa447008da84d7486c0c05a/artifacts/episodes_eval/0&rsquo;]</p><a href=#definitions><h3 id=definitions><span class=hanchor arialabel=Anchor># </span>Definitions</h3></a><p><strong>Episode</strong>:: oneÂ <strong>episode</strong>Â = one a sequence of states, actions and rewards, which ends with terminal state. For example, playing an entire game can be considered as one episode, the terminal state being reached when one player loses/wins/draws. Sometime, one may prefer to define one episode as several games (
<a href=http://karpathy.github.io/2016/05/31/rl/ rel=noopener>example</a>: &ldquo;each episode is a few dozen games, because the games go up to score of 21 for either player&rdquo;).</p><a href=#usefull-commands><h2 id=usefull-commands><span class=hanchor arialabel=Anchor># </span>Usefull Commands</h2></a><a href=#launch-training><h4 id=launch-training><span class=hanchor arialabel=Anchor># </span>Launch Training</h4></a><p><code>python launch.py --config defaults minigrid debug --env_id MiniGrid-Empty-8x8-v0 --probe_model none</code></p><a href=#launch-model-extraction-and-evaluation><h4 id=launch-model-extraction-and-evaluation><span class=hanchor arialabel=Anchor># </span>Launch model extraction and evaluation</h4></a><p><code>python extract_model.py --config defaults minigrid debug --env_id MiniGrid-Empty-8x8-v0 --probe_model none</code></p><a href=#gif-creation-1><h4 id=gif-creation-1><span class=hanchor arialabel=Anchor># </span>Gif Creation</h4></a><p>Tutorial : Minigrid
<a href=https://goodboychan.github.io/python/pytorch/reinforcement_learning/2020/08/06/03-Policy-Gradient-With-Gym-MiniGrid.html rel=noopener>https://goodboychan.github.io/python/pytorch/reinforcement_learning/2020/08/06/03-Policy-Gradient-With-Gym-MiniGrid.html</a></p><p>Gymnasium Tutorial :
<a href=https://gymnasium.farama.org/content/basic_usage/ rel=noopener>https://gymnasium.farama.org/content/basic_usage/</a></p><a href=#metrics><h2 id=metrics><span class=hanchor arialabel=Anchor># </span>Metrics</h2></a><p>Agent/Return ?</p><a href=#dream-interpretation><h2 id=dream-interpretation><span class=hanchor arialabel=Anchor># </span>Dream interpretation</h2></a><p>dream_alien_2000001.gif is perfect
dream_alien_2098001.gif is terrible
dream_alien_2208001.gif is a bit better
dream_alien_2500001.gif can dream in the other level</p><p>Has trouble adapting to new stages of the game</p><p>Problem if extract_model.py
the model becomes progressively worse as we may have the $h$ and $z$embedding not corresponding to what the model is expecting</p><p>Identified $h$ and $z$ in the model, find a way to extract h and z ?</p><p><a href=/quartz/Science/Machine-Learning-Rescources#visualisation rel=noopener class=internal-link data-src=/quartz/Science/Machine-Learning-Rescources>Machine Learning Rescources</a></p><a href=#questions><h1 id=questions><span class=hanchor arialabel=Anchor># </span>Questions</h1></a><p>Metrics</p><p>Open and closes loop</p><a href=#quick-notes><h2 id=quick-notes><span class=hanchor arialabel=Anchor># </span>Quick notes</h2></a><p>Culprite
8ba12c353cc143c7bfbced48dba41d4a</p><a href=#ideas><h1 id=ideas><span class=hanchor arialabel=Anchor># </span>Ideas</h1></a><p>Take value policy map and learn it with a CNN
Pixelate the space more to get subgoals
Change gamma</p><p>Widad we should do an auto encoder on millions of image of walls(SIM CLR style)
Plus pretraining ?
Then train with labels</p></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://theo-michel.github.io/quartz/js/graph.6579af7b10c818dbd2ca038702db0224.js></script></div></div><div id=contact_buttons><footer><p>Made by Jacky Zhao using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, Â© 2023</p><ul><li><a href=https://theo-michel.github.io/quartz/>Home</a></li><li><a href=https://twitter.com/_jzhao>Twitter</a></li><li><a href=https://github.com/jackyzha0>GitHub</a></li></ul></footer></div></div></body></html>